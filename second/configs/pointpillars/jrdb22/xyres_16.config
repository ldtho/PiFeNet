model: {
  second: {
    network_class_name: "VoxelNet"
    voxel_generator {
      full_empty_part_with_mean: false
      point_cloud_range : [-39.68, -39.68, -2, 39.68, 39.68, 2]
      voxel_size : [0.16, 0.16, 4]
      max_number_of_points_per_voxel : 100
    }
    voxel_feature_extractor: {
      module_class_name: "PillarFeatureNet"
      num_filters: [64]
      with_distance: false
      num_input_features: 4
    }
    middle_feature_extractor: {
      module_class_name: "PointPillarsScatter"
      downsample_factor: 1
      num_input_features: 64
    }
    rpn: {
      module_class_name: "RPNV2"
      layer_nums: [3, 5, 5]
      layer_strides: [1, 2, 2]
      num_filters: [64, 128, 256]
      upsample_strides: [1, 2, 4]
      num_upsample_filters: [128, 128, 128]
      use_groupnorm: false
      num_groups: 32
      num_input_features: 64
    }
    loss: {
      classification_loss: {
        weighted_sigmoid_focal: {
          alpha: 0.25
          gamma: 2.0
          anchorwise_output: true
        }
      }
      localization_loss: {
        weighted_smooth_l1: {
          sigma: 3.0
          code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
        }
      }
      classification_weight: 1.0
      localization_weight: 2.0
    }
    num_point_features: 3 # model's num point feature should be independent of dataset
    # Outputs
    use_sigmoid_score: true
    encode_background_as_zeros: true
    encode_rad_error_by_sin: true

    use_direction_classifier: true
    direction_loss_weight: 0.2
    num_direction_bins: 2
    direction_limit_offset: 0 #1

    # Loss
    pos_class_weight: 1.0
    neg_class_weight: 1.0

    loss_norm_type: NormByNumPositives
    # Postprocess
    post_center_limit_range: [-39.68, -39.68, -2, 39.68, 39.68, 2]
    nms_class_agnostic: false # only valid in multi-class nms
    box_coder: {
      ground_box3d_coder: {
        linear_dim: false
        encode_angle_vector: false
      }
    }
    target_assigner: {
      class_settings: {
        anchor_generator_stride: {
          sizes: [0.92536718, 0.51667982, 1.70884644] # wlh
          strides: [0.16, 0.16, 0.0] # if generate only 1 z_center, z_stride will be ignored
          offsets: [-39.6, -39.6, -2.17951978] # origin_offset + strides / 2
          rotations: [0, 1.57] # 0, pi/2
        }
        #anchor_generator_range: {
        #  sizes: [0.92536718, 0.51667982, 1.70884644] # wlh_camera
        #  anchor_ranges: [-20, -20, 0.17951978, 20, 20, 0.17951978]
        #  rotations: [0, 1.57] # DON'T modify this unless you are very familiar with my code.
        #  # custom_values: [0, 0] # velocity vector base value
        #}

        matched_threshold : 0.5
        unmatched_threshold : 0.35
        class_name: "Pedestrian"
        use_rotate_nms: false
        use_multi_class_nms: false
        nms_pre_max_size: 1000
        nms_post_max_size: 300
        nms_score_threshold: 0.05
        nms_iou_threshold: 0.5
        region_similarity_calculator: {
          nearest_iou_similarity: {
          }
        }
      }
      sample_positive_fraction : -1
      sample_size : 512
      assign_per_class: true
    }
  }
}

train_input_reader: {
  dataset: {
    dataset_class_name: "JRDBDataset"
    kitti_info_path: "/home/tho/datasets/JRDB2022_converted/jrdb22_infos_train.pkl"
    kitti_root_path: "/home/tho/datasets/JRDB2022_converted"
  }

  batch_size: 2
  preprocess: {
    max_number_of_voxels: 30000
    shuffle_points: true
    num_workers: 8
    groundtruth_localization_noise_std: [0.25, 0.25, 0.25]
    groundtruth_rotation_uniform_noise: [-0.15707963267, 0.15707963267]
    global_rotation_uniform_noise: [-0.78539816, 0.78539816]
    global_scaling_uniform_noise: [0.95, 1.05]
    global_random_rotation_range_per_object: [0, 0]
    global_translate_noise_std: [0.2, 0.2, 0.2]
    anchor_area_threshold: 1
    remove_points_after_sample: false
    groundtruth_points_drop_percentage: 0.0
    groundtruth_drop_max_keep_points: 15
    remove_unknown_examples: false
    sample_importance: 1.0
    random_flip_x: false
    random_flip_y: true
    remove_environment: false
    database_sampler {
      database_info_path: "/home/tho/datasets/JRDB2022_converted/kitti_dbinfos_train.pkl"
      sample_groups {
        name_to_max_num {
          key: "Pedestrian"
          value: 30
        }
      }
      database_prep_steps {
        filter_by_min_num_points {
          min_num_point_pairs {
            key: "Pedestrian"
            value: 10
          }
        }
      }
      database_prep_steps {
        filter_by_difficulty {
          removed_difficulties: [-1]
        }
      }
      global_random_rotation_range_per_object: [0, 0]
      rate: 1.0
    }
  }
}

train_config: {
  optimizer: {
    adamW_optimizer: {
      learning_rate: {
        one_cycle: {
          lr_max: 3e-3
          moms: [0.95, 0.85]
          div_factor: 10.0
          pct_start: 0.25
        }
      }
      weight_decay: 0.01 # 0.0001
      amsgrad: false
    }
    fixed_weight_decay: false
    use_moving_average: false
  }
  steps: 434880 #652320 #289920 # 21744/2 steps per epoch * 60 epochs
  steps_per_eval: 54360 #14496 #7248 # 21744/3 steps per epoch * 5 epochs
  save_checkpoints_secs : 1800 # half hour
  save_summary_steps : 30
  enable_mixed_precision: false
  loss_scale_factor: -1
  clear_metrics_every_epoch: true
}

eval_input_reader: {
  dataset: {
    dataset_class_name: "JRDBDataset"
    #kitti_info_path: "/home/tho/datasets/JRDB2022_converted/jrdb22_infos_val.pkl"
    kitti_info_path: "/home/tho/datasets/JRDB2022_converted/jrdb22_infos_test.pkl"
    kitti_root_path: "/home/tho/datasets/JRDB2022_converted"
  }
  batch_size: 2
  
  preprocess: {
    max_number_of_voxels: 30000
    shuffle_points: false
    num_workers: 8
    anchor_area_threshold: 1
    remove_environment: false
  }
}
